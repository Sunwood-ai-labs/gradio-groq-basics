import gradio as gr
import groq
import os
import io
import numpy as np
import soundfile as sf
from PIL import Image
import base64

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰GROQ_API_KEYã‚’å–å¾—
api_key = os.environ.get("GROQ_API_KEY")
if not api_key:
    raise ValueError("GROQ_API_KEYç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

# Groqã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = groq.Client(api_key=api_key)

def transcribe_audio(audio):
    if audio is None:
        return "éŸ³å£°ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", ""
    sr, y = audio

    # ã‚¹ãƒ†ãƒ¬ã‚ªã®å ´åˆã¯ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
    if y.ndim > 1:
        y = y.mean(axis=1)

    # éŸ³å£°ã®æ­£è¦åŒ–
    y = y.astype(np.float32)
    y /= np.max(np.abs(y))

    # éŸ³å£°ã‚’ãƒãƒƒãƒ•ã‚¡ã«æ›¸ãè¾¼ã¿
    buffer = io.BytesIO()
    sf.write(buffer, y, sr, format='wav')
    buffer.seek(0)

    try:
        # Whisperå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦æ–‡å­—èµ·ã“ã—
        completion = client.audio.transcriptions.create(
            model="whisper-large-v3-turbo",
            file=("audio.wav", buffer),
            response_format="text"
        )
        transcription = completion
    except Exception as e:
        transcription = f"æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)}"

    response = generate_response(transcription)
    return transcription, response

def generate_response(transcription):
    if not transcription or transcription.startswith("ã‚¨ãƒ©ãƒ¼"):
        return "æœ‰åŠ¹ãªæ–‡å­—èµ·ã“ã—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚‚ã†ä¸€åº¦è©±ã—ã¦ãã ã•ã„ã€‚"

    try:
        # Llama 3.1 70Bãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
        completion = client.chat.completions.create(
            model="llama-3.1-70b-versatile",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯å½¹ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                {"role": "user", "content": transcription}
            ],
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"

def analyze_image(image):
    if image is None:
        return "ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", None

    # numpyé…åˆ—ã‚’PIL Imageã«å¤‰æ›
    image_pil = Image.fromarray(image.astype('uint8'), 'RGB')

    # PILç”»åƒã‚’base64ã«å¤‰æ›
    buffered = io.BytesIO()
    image_pil.save(buffered, format="JPEG")
    base64_image = base64.b64encode(buffered.getvalue()).decode('utf-8')

    try:
        # Llama 3.2 11B Visionãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‚’åˆ†æ
        chat_completion = client.chat.completions.create(
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "ã“ã®ç”»åƒã‚’è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}",
                            },
                        },
                    ],
                }
            ],
            model="llama-3.2-11b-vision-preview",
        )
        description = chat_completion.choices[0].message.content
    except Exception as e:
        description = f"ç”»åƒåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"

    return description

def respond(message, chat_history):
    if chat_history is None:
        chat_history = []

    # APIã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’æº–å‚™
    messages = []
    for user_msg, assistant_msg in chat_history:
        messages.append({"role": "user", "content": user_msg})
        messages.append({"role": "assistant", "content": assistant_msg})

    messages.append({"role": "user", "content": message})

    try:
        # Llama 3.1 70Bãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’ç”Ÿæˆ
        completion = client.chat.completions.create(
            model="llama-3.1-70b-versatile",
            messages=messages,
        )
        assistant_message = completion.choices[0].message.content
        chat_history.append((message, assistant_message))
    except Exception as e:
        assistant_message = f"ã‚¨ãƒ©ãƒ¼: {str(e)}"
        chat_history.append((message, assistant_message))

    return "", chat_history, chat_history  # çŠ¶æ…‹ã‚’3ç•ªç›®ã®å‡ºåŠ›ã¨ã—ã¦è¿”ã™

# Groqãƒãƒƒã‚¸ã¨ã‚«ãƒ©ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ ç”¨ã®ã‚«ã‚¹ã‚¿ãƒ CSS
custom_css = """
.gradio-container {
    background-color: #f5f5f5;
}
.gr-button-primary {
    background-color: #f55036 !important;
    border-color: #f55036 !important;
}
#groq-badge {
    position: fixed;
    bottom: 20px;
    right: 20px;
    z-index: 1000;
}
"""

with gr.Blocks(css=custom_css) as demo:
    gr.Markdown("# ğŸ™ï¸ Groq x Gradio ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« Llama-3.2 ãŠã‚ˆã³ Whisper")

    with gr.Tab("éŸ³å£°"):
        gr.Markdown("## AIã¨ä¼šè©±ã™ã‚‹")
        with gr.Row():
            audio_input = gr.Audio(type="numpy", label="è©±ã™ã‹éŸ³å£°ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        with gr.Row():
            transcription_output = gr.Textbox(label="æ–‡å­—èµ·ã“ã—")
            response_output = gr.Textbox(label="AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”")
        process_button = gr.Button("å‡¦ç†", variant="primary")
        process_button.click(
            transcribe_audio,
            inputs=audio_input,
            outputs=[transcription_output, response_output]
        )

    with gr.Tab("ç”»åƒ"):
        gr.Markdown("## åˆ†æç”¨ã®ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        with gr.Row():
            image_input = gr.Image(type="numpy", label="ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        with gr.Row():
            image_description_output = gr.Textbox(label="ç”»åƒã®èª¬æ˜")
        analyze_button = gr.Button("ç”»åƒã‚’åˆ†æ", variant="primary")
        analyze_button.click(
            analyze_image,
            inputs=image_input,
            outputs=[image_description_output]
        )

    with gr.Tab("ãƒãƒ£ãƒƒãƒˆ"):
        gr.Markdown("## AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ãƒãƒ£ãƒƒãƒˆ")
        chatbot = gr.Chatbot()
        state = gr.State([])  # ãƒãƒ£ãƒƒãƒˆã®çŠ¶æ…‹ã‚’åˆæœŸåŒ–
        with gr.Row():
            user_input = gr.Textbox(show_label=False, placeholder="ã“ã“ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›...", container=False)
            send_button = gr.Button("é€ä¿¡", variant="primary")
        send_button.click(
            respond,
            inputs=[user_input, state],
            outputs=[user_input, chatbot, state],
        )

    # Groqãƒãƒƒã‚¸ã‚’è¿½åŠ 
    gr.HTML("""
    <div id="groq-badge">
        <div style="color: #f55036; font-weight: bold;">GROQæä¾›</div>
    </div>
    """)

    gr.Markdown("""
    ## ã“ã®ã‚¢ãƒ—ãƒªã®ä½¿ã„æ–¹:

    ### éŸ³å£°ã‚¿ãƒ–
    1. ãƒã‚¤ã‚¯ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©±ã™ã‹ã€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    2. "å‡¦ç†"ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‹ã‚‰å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    3. æ–‡å­—èµ·ã“ã—ã¨AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ãŒã€ãã‚Œãã‚Œã®ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

    ### ç”»åƒã‚¿ãƒ–
    1. ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    2. "ç”»åƒã‚’åˆ†æ"ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ç”»åƒã®è©³ç´°ãªèª¬æ˜ã‚’å–å¾—ã—ã¾ã™ã€‚
    3. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒã¨ãã®èª¬æ˜ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

    ### ãƒãƒ£ãƒƒãƒˆã‚¿ãƒ–
    1. ä¸‹éƒ¨ã®ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¾ã™ã€‚
    2. "é€ä¿¡"ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨å¯¾è©±ã—ã¾ã™ã€‚
    3. ä¼šè©±ãŒãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
    """)

demo.launch()
